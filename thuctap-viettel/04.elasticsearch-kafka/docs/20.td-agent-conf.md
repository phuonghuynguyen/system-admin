


`replica.fetch.max.byte:` Nếu giá trị này nhỏ hơn message.max.byte thì replica sẽ không thể fetch dữ liệu từ main partition.

Broker tạo 1 vùng buffer replica.fetch.max.byte cho mỗi partition để replicate. Nếu giá trị replica.fetch.max.byte=1mb nhỏ hơn message.max.byte thì có thể xảy ra trường hợp phần buffer này không vừa 1 message ---> ko replicate được. Từ đó giá trị này nên lớn hơn message.max.byte.

<h2 style="color:orange">1.2. Sticky partitioner</h2>

Khi nhiều records được gửi tới cùng 1 partition, producer sẽ đóng lô chúng lại(batch). Trường `batch.size` điêu khiển kích thước lô, mặc định 16384kb. 

Batch size nhỏ sẽ khiến batching ít lại và ảnh hưởng throughput. Batchsize lớn quá sẽ dùng RAM phí phạm, vì mình sẽ luôn dùng RAM để làm buffer để batch.

- Trường `linger.ms` (default là 0, đơn vị ms) đặt thời gian đợi để record được đẩy thêm vào batch trước khi gửi batch đi. Mặc định, producer sẽ gửi batch đi ngay khi có 1 sender thread available. Kể cả khi chỉ có 1 message trong batch (chú ý rằng batch.size là giá trị max 1 batch). Nếu set linger.ms lớn hơn 0, vd 10 producer sẽ đợi 10ms trước khi gửi batch đi, ngay cả khi sender thread available. Điều này làm tăng latency nhưng cũng tăng throughput. Nhiều message (nhiều batch) sẽ làm tăng overhead.

- Câu hỏi: trong kafka setting, nếu linger.ms=0 và batch size mặc định =16384kb. Producer sẽ đợi ntn để gửi batch? Có phải nó sẽ đợi vĩnh viễn cho đến khi batch đầy mới gửi; hay là vì linger.ms = 0, nó sẽ ko đóng batch gì cả mà gửi luôn?
- Trả lời: Producer sẽ gửi half-full batch hoặc chỉ 1 message. Do đó, setting batch lớn sẽ không gây ra delay khi gửi message mà chỉ khiến dùng nhiều memory để buffer batch. Setting batch.size nhỏ sẽ thì nhiều overhead vì phải gửi message nhiều lần. Mặc định (linger.ms=0), producer sẽ gửi message ngay khi có thread available, ngay cả khi chỉ có 1 message trong batch.
Tham khảo: https://stackoverflow.com/questions/54193852/is-this-possible-producer-batch-size-max-request-size-broker-max-message-by
https://stackoverflow.com/questions/51521737/apache-kafka-linger-ms-and-batch-size-settings

<h2 style="color:orange">Configure td-agent</h2>
Config mẫu chạy production

    <match VTN_TraceSo.secLog>
      @type kafka2
      @id out_kafka
      @log_level warn
      get_kafka_client_log false

      #list of brokers
      brokers 10.254.138.3:9092,10.254.138.4:9092,10.254.138.10:9092

      # topic setting
      default_topic es.centralizedlog.Trace_So
      topic_key es.centralizedlog.Trace_So

      #buffer setting
      <buffer es.centralizedlog.Trace_So>
        @type memory
        chunk_limit_size 3m
        flush_at_shutdown true
        flush_interval 15s
        flush_thread_count 10
        flush_thread_interval 2
        flush_thread_burst_interval 1.0
        total_limit_size 250m
        chunk_full_threshold 0.95
        queued_chunks_limit_size 100
        overflow_action block
        retry_type periodic
        retry_wait 5s
        retry_timeout 48h
      </buffer>

      <inject>
        tag_key tag
        time_key fluentd_time
        time_type string
        time_format %Y-%m-%dT%H:%M:%S.%NZ
      </inject>

      # data type settings
      <format>
        @type json
      </format>

      # producer settings
      required_acks 1
      max_send_limit_bytes 250000
    </match>

Config sử dụng plugin kafka2: https://github.com/fluent/fluent-plugin-kafka

Buffer section tham khảo của hãng: https://docs.fluentd.org/v/1.0/configuration/buffer-section

Trong đó:
- chunk_limit_size 3m: (default 8m): đóng vai trò làm buffer để đẩy log (nếu không cấu hình trường max_send_limit_byte) thì có thể coi chunk = batch.size của producer.
- flush_interval 15s = linger.ms
- queued_chunks_limit_size 100: số lượng chunk hoạt động cùng lúc. --> queue =3x100=300mb
- overflow_action=block: nếu log đẩy vào tràn queue =300mb thì sẽ block ko nhận message nữa.
- flush_thread_count=10: số lượng chunk được đẩy đi hoạt động cùng lúc.
- flush_thread_interval=2s: thời gian đợi để đẩy chunk tiếp theo (nếu không có chunk nào trong queue)
- flush_thread_burst_interval: thời gian đợi để đẩy chunk tiếp theo (nếu có chunk trong queue)
- total_limit_size=250m: giới hạn queue =250mb < 300mb. Nếu queue lên đến mức này, tất cả operation sẽ fail với error.